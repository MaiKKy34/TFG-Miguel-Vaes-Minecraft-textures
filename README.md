# Texture Generation with Variational Autoencoder (VAE) - Final Degree Project Miguel
This project focuses on training an artificial intelligence model, specifically a Variational Autoencoder (VAE), to generate textures for video games. The objective is to leverage extensive knowledge of neural networks and the generative model VAE to create a robust texture generation system. The videogame choosen in this project is Minecraft but the code could be useful for other videogames textures by just changing the dataset the model is trained with.

## Features

- Implement the VAE using Python programming language.
- Use the power of PyTorch and torchvision libraries for neural network implementation.
- Train a Variational Autoencoder (VAE) model for texture generation.
- Generate textures and skins specifically tailored for the Minecraft video game.
- Integrate the generated textures into Minecraft for real-time observation and evaluation.
- Provide a diverse range of textures and skins due to Minecraft's wide selection.

## Project Structure

The project repository is organized as follows:

- `.idea/`: Contains a set of configuration files (. xml) for my project.
- `code_VAE/`: Includes the implementation of the Variational Autoencoder (VAE) model.
- `code_VAE_Convolutional/`: Includes the implementation of the Variational Autoencoder (VAE) model using convolutional neural networks for its training.
- `generated/`: Holds the generated textures and skins as output of the VAE.
- `modelos_MNIST_CIFAR/`: Contains models trained with MNIST and CIFAR10 datasets created while learning VAE implementation.
- `trained_models/`: Contains the VAE models trained to generate textures and skins.
